{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch gradio datasets -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DMe95UeH3ok",
        "outputId": "9002b1b9-57d9-421f-a0f7-309807f45972"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "vGE1Ot_3H-w6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "iyx1OZi3IA44"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "GXWiAkgCIEKj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text,\n",
        "                              return_tensors=\"pt\",\n",
        "                              max_length=1024,\n",
        "                              truncation=True).to(device)\n",
        "\n",
        "    summary_ids = model.generate(inputs,\n",
        "                                 max_length=150,\n",
        "                                 min_length=40,\n",
        "                                 length_penalty=2.0,\n",
        "                                 num_beams=4,\n",
        "                                 early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "PTK0QvMcIGfw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=summarize,\n",
        "    inputs=gr.Textbox(lines=15, label=\"Enter text to summarize\"),\n",
        "    outputs=gr.Textbox(label=\"Summary\"),\n",
        "    title=\"üìù T5 Text Summarizer\",\n",
        "    description=\"Enter a long article or paragraph and get a summarized version using the T5-small model.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "kAOeu0fRII3S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "gQPmmv0HIOOk",
        "outputId": "f53fc8de-e3db-408b-92ad-de868fcf76ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a01c62369400d0e72e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a01c62369400d0e72e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}